{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda9f3da-8ff9-4bae-a3bc-16107632a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql+pymysql://exxxxp:@local/order_bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63a6879-b90f-4ffe-9499-64d854258fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders']\n"
     ]
    }
   ],
   "source": [
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2efb2cf2-9a61-4a13-ac05-be5cbf63b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE orders (\n",
      "\torder_id BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT, \n",
      "\tcustomer_name VARCHAR(100), \n",
      "\tstatus VARCHAR(50), \n",
      "\tdelivery_date DATE, \n",
      "\trefund_status VARCHAR(50), \n",
      "\tpayment_method VARCHAR(50), \n",
      "\tPRIMARY KEY (order_id)\n",
      ")COLLATE utf8mb4_general_ci DEFAULT CHARSET=utf8mb4 ENGINE=InnoDB\n",
      "\n",
      "/*\n",
      "3 rows from orders table:\n",
      "order_id\tcustomer_name\tstatus\tdelivery_date\trefund_status\tpayment_method\n",
      "1\tArshad Anwar\tDelivered\t2025-07-01\tNo Refund\tCredit Card\n",
      "2\tBob Smith\tPending\tNone\tNo Refund\tPayPal\n",
      "3\tCharlie Brown\tShipped\t2025-07-28\tNo Refund\tDebit Card\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "print(db.get_table_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a458b786-f1e5-4754-a9a4-85a8e0d25a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\",\n",
    "               api_key=\"\",\n",
    "               temperature=0,\n",
    "               max_retries=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af891d7-4899-44fe-9ea7-e2f3cec97933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_message = \"\"\"\n",
    "Given an input question, create a syntactically correct {dialect} query to\n",
    "run to help find the answer. Unless the user specifies in his question a\n",
    "specific number of examples they wish to obtain, always limit your query to\n",
    "at most {top_k} results. You can order the results by a relevant column to\n",
    "return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for a the\n",
    "few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema\n",
    "description. Be careful to not query for columns that do not exist. Also,\n",
    "pay attention to which column is in which table.\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Question: {input}\"\n",
    "\n",
    "query_prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b45788d-4efa-4f0a-aaaf-2d80d8ecf3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to\n",
      "run to help find the answer. Unless the user specifies in his question a\n",
      "specific number of examples they wish to obtain, always limit your query to\n",
      "at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to\n",
      "return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the\n",
      "few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema\n",
      "description. Be careful to not query for columns that do not exist. Also,\n",
      "pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for message in query_prompt_template.messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd316d02-4ed6-4f07-9f41-1c1814b24555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "# Create SQL Database Chain\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, return_direct=True)\n",
    "result = db_chain.invoke({\"query\": \"Arshad Anwar order details?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955261a5-4cc5-4d32-bcbd-6daa71bab21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"mysql+pymysql:///order_bot\")\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize LLM (Ollama)\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\",\n",
    "               api_key=\"hided due to security\",\n",
    "               temperature=0,\n",
    "               max_retries=2)\n",
    "\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "# Create SQL Database Chain\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, return_direct=True)\n",
    "result = db_chain.invoke({\"query\": \"Arshad Anwar order details?\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80cd9a-fab3-4b28-a6c5-2028bfd83490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import logging\n",
    "\n",
    "# ✅ Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ✅ Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "DB_URI = os.getenv(\"DB_URI\", \"_bot\")\n",
    "GROQ_API_KEY = \"\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # ✅ Connect to database\n",
    "        db = SQLDatabase.from_uri(DB_URI)\n",
    "        logging.info(\"✅ Database connected successfully\")\n",
    "\n",
    "        # ✅ Initialize LLM\n",
    "        llm = ChatGroq(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            api_key=GROQ_API_KEY,\n",
    "            temperature=0,\n",
    "            max_retries=2\n",
    "        )\n",
    "\n",
    "        # ✅ Define a structured prompt template\n",
    "        template = \"\"\"\n",
    "        You are an AI assistant that converts natural language questions into SQL queries\n",
    "        and retrieves results from the database.\n",
    "        \n",
    "        Use the database schema and context to generate accurate SQL queries.\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "\n",
    "        # ✅ Create SQL Database Chain\n",
    "        db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=False, return_direct=True)\n",
    "\n",
    "        # ✅ Get user query\n",
    "        user_query = \"Arshad Anwar order details?\"\n",
    "        formatted_query = prompt.format(question=user_query)\n",
    "\n",
    "        raw_result = result.get(\"result\", \"\")\n",
    "        clean_result = raw_result.strip(\"[]\")\n",
    "        print(\"\\n✅ Clean Result:\\n\", clean_result)\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582609c4-5d99-4106-93ad-23a22ee6d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import logging\n",
    "\n",
    "# ✅ Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ✅ Load environment variables\n",
    "load_dotenv()\n",
    "DB_URI = os.getenv(\"DB_URI\", \"mysql+pymysql:/\")\n",
    "GROQ_API_KEY = \"\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # ✅ Connect to database\n",
    "        db = SQLDatabase.from_uri(DB_URI)\n",
    "        logging.info(\"✅ Database connected successfully\")\n",
    "\n",
    "        # ✅ Initialize LLM\n",
    "        llm = ChatGroq(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            api_key=GROQ_API_KEY,\n",
    "            temperature=0,\n",
    "            max_retries=2\n",
    "        )\n",
    "\n",
    "        # ✅ Define structured prompt\n",
    "        template = \"\"\"\n",
    "        You are an AI assistant that converts natural language questions into SQL queries\n",
    "        and retrieves results from the database.\n",
    "        \n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(input_variables=[\"question\"], template=template)\n",
    "\n",
    "        # ✅ Create SQL Database Chain\n",
    "        db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=False, return_direct=True)\n",
    "\n",
    "        # ✅ User query\n",
    "        user_query = \"Arshad Anwar order details?\"\n",
    "        formatted_query = prompt.format(question=user_query)\n",
    "\n",
    "        # ✅ Execute\n",
    "        result = db_chain.invoke({\"query\": formatted_query})\n",
    "\n",
    "        # ✅ Extract and clean result\n",
    "        raw_result = result.get(\"result\", \"\")\n",
    "        clean_result = raw_result.strip(\"[]\")\n",
    "        print(\"\\nResult:\\n\", clean_result)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51f8102-5cab-4b22-9b35-3c3bf9ee7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d91eb-e29f-4e8e-977b-91a9831798a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainkernel",
   "language": "python",
   "name": "langchainkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
