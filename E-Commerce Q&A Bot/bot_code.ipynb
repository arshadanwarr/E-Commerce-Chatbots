{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971136aa-1696-48fd-bc30-adb087b318fd",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460b4d03-31f6-4559-aa27-da0a18ff05e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain_community\\document_loaders\\web_base.py:299: UserWarning: For better logging of progress, `pip install tqdm`\n",
      "  warnings.warn(\"For better logging of progress, `pip install tqdm`\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'source': 'https://www.amazon.com/'}\n",
      "\n",
      "First 500 chars:\n",
      "Skip to | Main content | Keyboard shortcuts | Search | alt | + | / | Cart | shift | + | alt | + | C | Home | shift | + | alt | + | H | Orders | shift | + | alt | + | O | Show/Hide shortcuts | shift | + | alt | + | Z | To move between items, use your keyboard's up or down arrows. | .us | Deliver to | Pakistan | All | Select the department you want to search in | All Departments | Arts & Crafts | Automotive | Baby | Beauty & Personal Care | Books | Boys' Fashion | Computers | Deals | Digital Music\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "page_url = \"https://www.amazon.com/\"\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=[page_url],\n",
    "    bs_kwargs={\n",
    "        \"parse_only\": bs4.SoupStrainer(\"body\"),  # Parse the body instead of a specific class\n",
    "    },\n",
    "    bs_get_text_kwargs={\"separator\": \" | \", \"strip\": True},\n",
    ")\n",
    "\n",
    "docs = []\n",
    "\n",
    "async for doc in loader.alazy_load():\n",
    "    docs.append(doc)\n",
    "\n",
    "if docs:\n",
    "    print(f\"Metadata: {docs[0].metadata}\\n\")\n",
    "    print(f\"First 500 chars:\\n{docs[0].page_content[:500]}\")\n",
    "else:\n",
    "    print(\"No content extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc9c13-d568-4471-a3fe-4096eb600d48",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c383ace0-517e-4b6e-b68d-02e66f8fa7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 7 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab42e2a-4f41-46d5-954c-1aa5136952b1",
   "metadata": {},
   "source": [
    "## Embedding and Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8eb29a-2cfc-47e5-98c3-cc6d7a08e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text:v1.5\")\n",
    "\n",
    "vector = FAISS.from_documents(docs, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c651296-bb76-4bdd-bf51-672f6a4883db",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d344206c-9278-405d-ad7b-82aec3d949b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\", temprature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512b9f6-558d-4564-8827-0f68acc332d3",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7276fd-c437-48d8-aeb6-8dbab7a22d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "advanced_prompt = \"\"\"\n",
    "You are a helpful AI assistant answering questions based on the provided context and previous conversation.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18d7ef-2f9c-4da3-8001-bb7d31867864",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7606deb-c7cd-4dfc-942f-fb3afdb99984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import retrieval\n",
    "\n",
    "retriever = vector.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7deb7ee9-32d7-4a4c-b631-fb9cec99e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laptop Valley\\AppData\\Local\\Temp\\ipykernel_5684\\1275336335.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfc7fe-a951-42a1-923f-82a3f21d4d14",
   "metadata": {},
   "source": [
    "## Retrievel QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28be2628-8eab-48c0-8347-f217baafbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\n",
    "        \"prompt\": PromptTemplate.from_template(advanced_prompt)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42356cbe-f6c9-402a-9034-dc193f24aeae",
   "metadata": {},
   "source": [
    "## Run the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9a1f6ba-8e1b-4b5f-b0cf-2c5ecd861d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "454ba100-8384-4de0-bd53-529205a31e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FAISS index from disk.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# ---- Load or Build FAISS ----\n",
    "def build_or_load_vectorstore(url):\n",
    "    embedding = OllamaEmbeddings(model=\"all-minilm:22m\")  # Faster embeddings\n",
    "    index_path = \"faiss_index_new\"\n",
    "\n",
    "    try:\n",
    "        vector_store = FAISS.load_local(index_path, embedding, allow_dangerous_deserialization=True)\n",
    "        print(\"Loaded FAISS index from disk.\")\n",
    "    except:\n",
    "        print(\"Building FAISS index...\")\n",
    "        loader = WebBaseLoader(web_paths=[url], bs_kwargs={\"parse_only\": bs4.SoupStrainer(\"body\")})\n",
    "        docs = list(loader.load())\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        splits = splitter.split_documents(docs)\n",
    "        vector_store = FAISS.from_documents(splits, embedding)\n",
    "        vector_store.save_local(index_path)\n",
    "        print(\"Saved FAISS index to disk.\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "# ---- LLM ----\n",
    "def create_llm():\n",
    "    return ChatOllama(model=\"tinyllama:1.1b\", temperature=0, max_tokens=300, streaming=True)\n",
    "\n",
    "# ---- Prompt ----\n",
    "def create_advanced_prompt():\n",
    "    template = \"\"\"\n",
    "    \n",
    "    You are a helpful AI assistant answering questions based on the provided context and previous conversation.\n",
    "    Only return the final answer.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Chat History:\n",
    "    {chat_history}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "\n",
    "    Helpful Answer:\n",
    "\"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"chat_history\", \"query\"])\n",
    "\n",
    "# ---- QA Chain ----\n",
    "def create_qa_chain(llm, retriever, prompt):\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "# Usage\n",
    "url = \"https://www.amazon.com\"\n",
    "vector_store = build_or_load_vectorstore(url)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "llm = create_llm()\n",
    "prompt = create_advanced_prompt()\n",
    "qa_chain = create_qa_chain(llm, retriever, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a23f4074-183a-4cc2-9522-d698206ef868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Amazon is an online retail giant that offers a wide range of products for purchase, including books, electronics, clothing, household goods, and more. It was founded in 1994 by Jeff Bezos and has since grown into one of the largest e-commerce companies in the world with over 200 million active customers globally. Amazon's mission is to be Earth's most customer-centric company, helping people find what they need, getting it right, every time.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Amazon?\"\n",
    "answer = qa_chain.invoke({\"question\": query, \"chat_history\": []})\n",
    "print(\"Answer:\", answer[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ea04a-1df0-42ae-bc6a-92f7bb946464",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89697542-f063-4153-954c-0053555f5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bd565-40b9-4a86-a6f4-7aea02ffa4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainkernel",
   "language": "python",
   "name": "langchainkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
